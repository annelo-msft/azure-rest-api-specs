openapi: 3.0.0
info:
  title: Azure OpenAI API
  description: Azure OpenAI APIs for completions and search
  version: 2023-05-15
tags: []
paths:
  /deployments/{deploymentId}/chat/completions:
    post:
      operationId: getChatCompletions
      description: |-
        Gets chat completions for the provided chat messages.
        Completions support a wide variety of tasks and generate text that continues from or "completes"
        provided prompt data.
      parameters:
        - $ref: '#/components/parameters/Azure.Core.Foundations.ApiVersionParameter'
        - name: deploymentId
          in: path
          required: true
          description: Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletions'
        default:
          description: An unexpected error response.
          headers:
            x-ms-error-code:
              required: false
              description: String error code indicating what went wrong.
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Azure.Core.Foundations.ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionsOptions'
  /deployments/{deploymentId}/completions:
    post:
      operationId: getCompletions
      description: |-
        Gets completions for the provided input prompts.
        Completions support a wide variety of tasks and generate text that continues from or "completes"
        provided prompt data.
      parameters:
        - $ref: '#/components/parameters/Azure.Core.Foundations.ApiVersionParameter'
        - name: deploymentId
          in: path
          required: true
          description: Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Completions'
        default:
          description: An unexpected error response.
          headers:
            x-ms-error-code:
              required: false
              description: String error code indicating what went wrong.
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Azure.Core.Foundations.ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionsOptions'
  /deployments/{deploymentId}/embeddings:
    post:
      operationId: getEmbeddings
      description: Return the embeddings for a given prompt.
      parameters:
        - $ref: '#/components/parameters/Azure.Core.Foundations.ApiVersionParameter'
        - name: deploymentId
          in: path
          required: true
          description: Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Embeddings'
        default:
          description: An unexpected error response.
          headers:
            x-ms-error-code:
              required: false
              description: String error code indicating what went wrong.
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Azure.Core.Foundations.ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingsOptions'
security:
  - ApiKeyAuth: []
  - OAuth2Auth:
      - https://cognitiveservices.azure.com/.default
components:
  parameters:
    Azure.Core.Foundations.ApiVersionParameter:
      name: api-version
      in: query
      required: true
      description: The API version to use for this operation.
      schema:
        type: string
        minLength: 1
  schemas:
    Azure.Core.Foundations.Error:
      type: object
      required:
        - code
        - message
      properties:
        code:
          type: string
          description: One of a server-defined set of error codes.
        message:
          type: string
          description: A human-readable representation of the error.
        target:
          type: string
          description: The target of the error.
        details:
          type: array
          items:
            $ref: '#/components/schemas/Azure.Core.Foundations.Error'
          description: An array of details about specific errors that led to this reported error.
        innererror:
          allOf:
            - $ref: '#/components/schemas/Azure.Core.Foundations.InnerError'
          description: An object containing more specific information than the current object about the error.
      description: The error object.
    Azure.Core.Foundations.ErrorResponse:
      type: object
      required:
        - error
      properties:
        error:
          allOf:
            - $ref: '#/components/schemas/Azure.Core.Foundations.Error'
          description: The error object.
      description: A response containing error details.
    Azure.Core.Foundations.InnerError:
      type: object
      properties:
        code:
          type: string
          description: One of a server-defined set of error codes.
        innererror:
          allOf:
            - $ref: '#/components/schemas/Azure.Core.Foundations.InnerError'
          description: Inner error.
      description: An object containing more specific information about the error. As per Microsoft One API guidelines - https://github.com/Microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses.
    AzureOpenAIOperationState:
      anyOf:
        - type: string
        - type: string
          enum:
            - notRunning
            - running
            - succeeded
            - canceled
            - failed
      description: The state of a job or item.
    ChatChoice:
      type: object
      required:
        - index
        - finish_reason
      properties:
        message:
          allOf:
            - $ref: '#/components/schemas/ChatResponseMessage'
          description: The chat message for a given chat completions prompt.
        index:
          type: integer
          format: int32
          description: The ordered index associated with this chat completions choice.
        finish_reason:
          oneOf:
            - $ref: '#/components/schemas/CompletionsFinishReason'
          nullable: true
          description: The reason that this chat completions choice completed its generated.
        delta:
          allOf:
            - $ref: '#/components/schemas/ChatResponseMessage'
          description: The delta message content for a streaming response.
      description: |-
        The representation of a single prompt completion as part of an overall chat completions request.
        Generally, `n` choices are generated per provided prompt with a default value of 1.
        Token limits and other settings may limit the number of choices generated.
    ChatCompletions:
      type: object
      required:
        - id
        - created
        - choices
        - usage
      properties:
        id:
          type: string
          description: A unique identifier associated with this chat completions response.
        created:
          type: integer
          format: unixtime
          description: |-
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatChoice'
          description: |-
            The collection of completions choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
        model:
          type: string
          description: The model name used for this completions request.
        usage:
          allOf:
            - $ref: '#/components/schemas/CompletionsUsage'
          description: Usage information for tokens processed and generated as part of this completions operation.
      description: |-
        Representation of the response data from a chat completions request.
        Completions support a wide variety of tasks and generate text that continues from or "completes"
        provided prompt data.
    ChatCompletionsNamedToolSelection:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          description: The object type.
      discriminator:
        propertyName: type
      description: An abstract representation of an explicit, named tool selection to use for a chat completions request.
    ChatCompletionsOptions:
      type: object
      required:
        - messages
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatRequestMessage'
          description: |-
            The collection of context messages associated with this chat completions request.
            Typical usage begins with a chat message for the System role that provides instructions for
            the behavior of the assistant, followed by alternating messages between the User and
            Assistant roles.
        max_tokens:
          type: integer
          format: int32
          description: The maximum number of tokens to generate.
        temperature:
          type: number
          format: float
          description: |-
            The sampling temperature to use that controls the apparent creativity of generated completions.
            Higher values will make output more random while lower values will make results more focused
            and deterministic.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
        top_p:
          type: number
          format: float
          description: |-
            An alternative to sampling with temperature called nucleus sampling. This value causes the
            model to consider the results of tokens with the provided probability mass. As an example, a
            value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
            considered.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
        logit_bias:
          type: object
          additionalProperties:
            type: integer
            format: int32
          description: |-
            A map between GPT token IDs and bias scores that influences the probability of specific tokens
            appearing in a completions response. Token IDs are computed via external tokenizer tools, while
            bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to
            a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias
            score varies by model.
        user:
          type: string
          description: |-
            An identifier for the caller or end user of the operation. This may be used for tracking
            or rate-limiting purposes.
        n:
          type: integer
          format: int32
          description: |-
            The number of chat completions choices that should be generated for a chat completions
            response.
            Because this setting can generate many completions, it may quickly consume your token quota.
            Use carefully and ensure reasonable settings for max_tokens and stop.
        stop:
          type: array
          items:
            type: string
          description: A collection of textual sequences that will end completions generation.
        presence_penalty:
          type: number
          format: float
          description: |-
            A value that influences the probability of generated tokens appearing based on their existing
            presence in generated text.
            Positive values will make tokens less likely to appear when they already exist and increase the
            model's likelihood to output new topics.
        frequency_penalty:
          type: number
          format: float
          description: |-
            A value that influences the probability of generated tokens appearing based on their cumulative
            frequency in generated text.
            Positive values will make tokens less likely to appear as their frequency increases and
            decrease the likelihood of the model repeating the same statements verbatim.
        stream:
          type: boolean
          description: A value indicating whether chat completions should be streamed for this request.
        model:
          type: string
          description: |-
            The model name to provide as part of this completions request.
            Not applicable to Azure OpenAI, where deployment information should be included in the Azure
            resource URI that's connected to.
      description: |-
        The configuration information for a chat completions request.
        Completions support a wide variety of tasks and generate text that continues from or "completes"
        provided prompt data.
    ChatMessageContentItem:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          description: The discriminated object type.
      discriminator:
        propertyName: type
        mapping:
          text: '#/components/schemas/ChatMessageTextContentItem'
      description: An abstract representation of a structured content item within a chat message.
    ChatMessageTextContentItem:
      type: object
      required:
        - type
        - text
      properties:
        type:
          type: string
          enum:
            - text
          description: "The discriminated object type: always 'text' for this type."
        text:
          type: string
          description: The content of the message.
      allOf:
        - $ref: '#/components/schemas/ChatMessageContentItem'
      description: A structured chat content item containing plain text.
    ChatRequestAssistantMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - assistant
          description: The chat role associated with this message, which is always 'assistant' for assistant messages.
        content:
          type: string
          nullable: true
          description: The content of the message.
        name:
          type: string
          description: An optional name for the participant.
      allOf:
        - $ref: '#/components/schemas/ChatRequestMessage'
      description: A request chat message representing response or action from the assistant.
    ChatRequestMessage:
      type: object
      required:
        - role
      properties:
        role:
          allOf:
            - $ref: '#/components/schemas/ChatRole'
          description: The chat role associated with this message.
      discriminator:
        propertyName: role
        mapping:
          system: '#/components/schemas/ChatRequestSystemMessage'
          user: '#/components/schemas/ChatRequestUserMessage'
          assistant: '#/components/schemas/ChatRequestAssistantMessage'
      description: An abstract representation of a chat message as provided in a request.
    ChatRequestSystemMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - system
          description: The chat role associated with this message, which is always 'system' for system messages.
        content:
          type: string
          description: The contents of the system message.
        name:
          type: string
          description: An optional name for the participant.
      allOf:
        - $ref: '#/components/schemas/ChatRequestMessage'
      description: |-
        A request chat message containing system instructions that influence how the model will generate a chat completions
        response.
    ChatRequestUserMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - user
          description: The chat role associated with this message, which is always 'user' for user messages.
        content:
          anyOf:
            - type: string
            - type: array
              items:
                $ref: '#/components/schemas/ChatMessageContentItem'
          description: The contents of the user message, with available input types varying by selected model.
        name:
          type: string
          description: An optional name for the participant.
      allOf:
        - $ref: '#/components/schemas/ChatRequestMessage'
      description: A request chat message representing user input to the assistant.
    ChatResponseMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          allOf:
            - $ref: '#/components/schemas/ChatRole'
          description: The chat role associated with the message.
        content:
          type: string
          nullable: true
          description: The content of the message.
      description: A representation of a chat message as received in a response.
    ChatRole:
      anyOf:
        - type: string
        - type: string
          enum:
            - system
            - assistant
            - user
      description: A description of the intended purpose of a message within a chat completions interaction.
    Choice:
      type: object
      required:
        - text
        - index
        - logprobs
        - finish_reason
      properties:
        text:
          type: string
          description: The generated text for a given completions prompt.
        index:
          type: integer
          format: int32
          description: The ordered index associated with this completions choice.
        logprobs:
          type: object
          allOf:
            - $ref: '#/components/schemas/CompletionsLogProbabilityModel'
          nullable: true
          description: The log probabilities model for tokens associated with this completions choice.
        finish_reason:
          oneOf:
            - $ref: '#/components/schemas/CompletionsFinishReason'
          nullable: true
          description: Reason for finishing
      description: |-
        The representation of a single prompt completion as part of an overall completions request.
        Generally, `n` choices are generated per provided prompt with a default value of 1.
        Token limits and other settings may limit the number of choices generated.
    Completions:
      type: object
      required:
        - id
        - created
        - choices
        - usage
      properties:
        id:
          type: string
          description: A unique identifier associated with this completions response.
        created:
          type: integer
          format: unixtime
          description: |-
            The first timestamp associated with generation activity for this completions response,
            represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
        choices:
          type: array
          items:
            $ref: '#/components/schemas/Choice'
          description: |-
            The collection of completions choices associated with this completions response.
            Generally, `n` choices are generated per provided prompt with a default value of 1.
            Token limits and other settings may limit the number of choices generated.
        usage:
          allOf:
            - $ref: '#/components/schemas/CompletionsUsage'
          description: Usage information for tokens processed and generated as part of this completions operation.
      description: |-
        Representation of the response data from a completions request.
        Completions support a wide variety of tasks and generate text that continues from or "completes"
        provided prompt data.
    CompletionsFinishReason:
      anyOf:
        - type: string
        - type: string
          enum:
            - stop
            - length
            - content_filter
      description: Representation of the manner in which a completions response concluded.
    CompletionsLogProbabilityModel:
      type: object
      required:
        - tokens
        - token_logprobs
        - top_logprobs
        - text_offset
      properties:
        tokens:
          type: array
          items:
            type: string
          description: The textual forms of tokens evaluated in this probability model.
        token_logprobs:
          type: array
          items:
            type: number
            format: float
            nullable: true
          description: A collection of log probability values for the tokens in this completions data.
        top_logprobs:
          type: array
          items:
            type: object
            additionalProperties:
              type: number
              format: float
              nullable: true
          description: A mapping of tokens to maximum log probability values in this completions data.
        text_offset:
          type: array
          items:
            type: integer
            format: int32
          description: The text offsets associated with tokens in this completions data.
      description: Representation of a log probabilities model for a completions generation.
    CompletionsOptions:
      type: object
      required:
        - prompt
      properties:
        prompt:
          type: array
          items:
            type: string
          description: The prompts to generate completions from.
        max_tokens:
          type: integer
          format: int32
          description: The maximum number of tokens to generate.
        temperature:
          type: number
          format: float
          description: |-
            The sampling temperature to use that controls the apparent creativity of generated completions.
            Higher values will make output more random while lower values will make results more focused
            and deterministic.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
        top_p:
          type: number
          format: float
          description: |-
            An alternative to sampling with temperature called nucleus sampling. This value causes the
            model to consider the results of tokens with the provided probability mass. As an example, a
            value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
            considered.
            It is not recommended to modify temperature and top_p for the same completions request as the
            interaction of these two settings is difficult to predict.
        logit_bias:
          type: object
          additionalProperties:
            type: integer
            format: int32
          description: |-
            A map between GPT token IDs and bias scores that influences the probability of specific tokens
            appearing in a completions response. Token IDs are computed via external tokenizer tools, while
            bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to
            a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias
            score varies by model.
        user:
          type: string
          description: |-
            An identifier for the caller or end user of the operation. This may be used for tracking
            or rate-limiting purposes.
        n:
          type: integer
          format: int32
          description: |-
            The number of completions choices that should be generated per provided prompt as part of an
            overall completions response.
            Because this setting can generate many completions, it may quickly consume your token quota.
            Use carefully and ensure reasonable settings for max_tokens and stop.
        logprobs:
          type: integer
          format: int32
          description: |-
            A value that controls the emission of log probabilities for the provided number of most likely
            tokens within a completions response.
        suffix:
          type: string
          description: The suffix that comes after a completion of inserted text
        echo:
          type: boolean
          description: |-
            A value specifying whether completions responses should include input prompts as prefixes to
            their generated output.
        stop:
          type: array
          items:
            type: string
          description: A collection of textual sequences that will end completions generation.
        presence_penalty:
          type: number
          format: float
          description: |-
            A value that influences the probability of generated tokens appearing based on their existing
            presence in generated text.
            Positive values will make tokens less likely to appear when they already exist and increase the
            model's likelihood to output new topics.
        frequency_penalty:
          type: number
          format: float
          description: |-
            A value that influences the probability of generated tokens appearing based on their cumulative
            frequency in generated text.
            Positive values will make tokens less likely to appear as their frequency increases and
            decrease the likelihood of the model repeating the same statements verbatim.
        best_of:
          type: integer
          format: int32
          description: |-
            A value that controls how many completions will be internally generated prior to response
            formulation.
            When used together with n, best_of controls the number of candidate completions and must be
            greater than n.
            Because this setting can generate many completions, it may quickly consume your token quota.
            Use carefully and ensure reasonable settings for max_tokens and stop.
        stream:
          type: boolean
          description: A value indicating whether chat completions should be streamed for this request.
        model:
          type: string
          description: |-
            The model name to provide as part of this completions request.
            Not applicable to Azure OpenAI, where deployment information should be included in the Azure
            resource URI that's connected to.
      description: |-
        The configuration information for a completions request.
        Completions support a wide variety of tasks and generate text that continues from or "completes"
        provided prompt data.
    CompletionsUsage:
      type: object
      required:
        - completion_tokens
        - prompt_tokens
        - total_tokens
      properties:
        completion_tokens:
          type: integer
          format: int32
          description: The number of tokens generated across all completions emissions.
        prompt_tokens:
          type: integer
          format: int32
          description: The number of tokens in the provided prompts for the completions request.
        total_tokens:
          type: integer
          format: int32
          description: The total number of tokens processed for the completions request and response.
      description: |-
        Representation of the token counts processed for a completions request.
        Counts consider all tokens across prompts, choices, choice alternates, best_of generations, and
        other consumers.
    EmbeddingItem:
      type: object
      required:
        - embedding
        - index
      properties:
        embedding:
          type: array
          items:
            type: number
            format: float
          description: |-
            List of embeddings value for the input prompt. These represent a measurement of the
            vector-based relatedness of the provided input.
        index:
          type: integer
          format: int32
          description: Index of the prompt to which the EmbeddingItem corresponds.
      description: Representation of a single embeddings relatedness comparison.
    Embeddings:
      type: object
      required:
        - data
        - usage
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/EmbeddingItem'
          description: Embedding values for the prompts submitted in the request.
        usage:
          allOf:
            - $ref: '#/components/schemas/EmbeddingsUsage'
          description: Usage counts for tokens input using the embeddings API.
      description: |-
        Representation of the response data from an embeddings request.
        Embeddings measure the relatedness of text strings and are commonly used for search, clustering,
        recommendations, and other similar scenarios.
    EmbeddingsOptions:
      type: object
      required:
        - input
      properties:
        user:
          type: string
          description: |-
            An identifier for the caller or end user of the operation. This may be used for tracking
            or rate-limiting purposes.
        model:
          type: string
          description: |-
            The model name to provide as part of this embeddings request.
            Not applicable to Azure OpenAI, where deployment information should be included in the Azure
            resource URI that's connected to.
        input:
          type: array
          items:
            type: string
          description: |-
            Input texts to get embeddings for, encoded as a an array of strings.
            Each input must not exceed 2048 tokens in length.

            Unless you are embedding code, we suggest replacing newlines (\n) in your input with a single space,
            as we have observed inferior results when newlines are present.
      description: |-
        The configuration information for an embeddings request.
        Embeddings measure the relatedness of text strings and are commonly used for search, clustering,
        recommendations, and other similar scenarios.
    EmbeddingsUsage:
      type: object
      required:
        - prompt_tokens
        - total_tokens
      properties:
        prompt_tokens:
          type: integer
          format: int32
          description: Number of tokens sent in the original request.
        total_tokens:
          type: integer
          format: int32
          description: Total number of tokens transacted in this request/response.
      description: Measurement of the amount of tokens used in this request and response.
    ServiceApiVersions:
      type: string
      enum:
        - 2022-12-01
        - 2023-05-15
        - 2023-06-01-preview
        - 2023-07-01-preview
        - 2024-02-15-preview
        - 2024-03-01-preview
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: api-key
    OAuth2Auth:
      type: oauth2
      flows:
        implicit:
          authorizationUrl: https://login.microsoftonline.com/common/oauth2/v2.0/authorize
          scopes:
            https://cognitiveservices.azure.com/.default: ''
servers:
  - url: '{endpoint}/openai'
    description: Azure OpenAI APIs for completions and search
    variables:
      endpoint:
        default: ''
        description: |-
          Supported Cognitive Services endpoints (protocol and hostname, for example:
          https://westus.api.cognitive.microsoft.com).
